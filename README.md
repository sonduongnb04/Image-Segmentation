# Dá»± Ã¡n PhÃ¢n Ä‘oáº¡n áº¢nh Giao ThÃ´ng sá»­ dá»¥ng Deep Learning

## ğŸ“‹ Tá»•ng quan

Dá»± Ã¡n phÃ¢n Ä‘oáº¡n áº£nh giao thÃ´ng (Traffic Image Segmentation) sá»­ dá»¥ng cÃ¡c mÃ´ hÃ¬nh Deep Learning tiÃªn tiáº¿n Ä‘á»ƒ phÃ¢n Ä‘oáº¡n cÃ¡c Ä‘á»‘i tÆ°á»£ng trong áº£nh giao thÃ´ng thÃ nh 12 lá»›p khÃ¡c nhau. Dá»± Ã¡n Ä‘Æ°á»£c xÃ¢y dá»±ng vá»›i hai pháº§n chÃ­nh:
- **ImageSegmentation**: Xá»­ lÃ½ dá»¯ liá»‡u, huáº¥n luyá»‡n vÃ  Ä‘Ã¡nh giÃ¡ mÃ´ hÃ¬nh
- **Webb**: Giao diá»‡n web hoÃ n chá»‰nh vá»›i Back-End API vÃ  Front-End ngÆ°á»i dÃ¹ng

## ğŸ¯ Má»¥c tiÃªu

- PhÃ¢n Ä‘oáº¡n chÃ­nh xÃ¡c cÃ¡c Ä‘á»‘i tÆ°á»£ng giao thÃ´ng trong áº£nh
- Há»— trá»£ 12 lá»›p Ä‘á»‘i tÆ°á»£ng: Báº§u trá»i, TÃ²a nhÃ , Cá»™t, ÄÆ°á»ng, Vá»‰a hÃ¨, CÃ¢y, Biá»ƒn bÃ¡o, HÃ ng rÃ o, Xe hÆ¡i, NgÆ°á»i Ä‘i bá»™, NgÆ°á»i Ä‘i xe Ä‘áº¡p, KhÃ´ng xÃ¡c Ä‘á»‹nh
- Cung cáº¥p giao diá»‡n web thÃ¢n thiá»‡n Ä‘á»ƒ sá»­ dá»¥ng mÃ´ hÃ¬nh
- Äáº¡t hiá»‡u suáº¥t cao vá»›i cÃ¡c metrics nhÆ° IoU, Dice Score, Pixel Accuracy

## ğŸ—ï¸ Kiáº¿n trÃºc Há»‡ thá»‘ng

```
Segmentation/
â”œâ”€â”€ ImageSegmentation/          # Pháº§n xá»­ lÃ½ dá»¯ liá»‡u vÃ  huáº¥n luyá»‡n mÃ´ hÃ¬nh
â”‚   â”œâ”€â”€ data.py                 # Xá»­ lÃ½ vÃ  chuáº©n bá»‹ dá»¯ liá»‡u CamVid
â”‚   â”œâ”€â”€ model.py                # MÃ´ hÃ¬nh UNet vÃ  training loop
â”‚   â”œâ”€â”€ unetPlus.py             # MÃ´ hÃ¬nh UNet++ vá»›i encoder pre-trained
â”‚   â”œâ”€â”€ demo.py                 # Script demo vÃ  test mÃ´ hÃ¬nh
â”‚   â”œâ”€â”€ processed.py            # Tiá»n xá»­ lÃ½ dá»¯ liá»‡u
â”‚   â”œâ”€â”€ CamVid/                 # Dá»¯ liá»‡u gá»‘c CamVid dataset
â”‚   â”œâ”€â”€ Camvid_processed/       # Dá»¯ liá»‡u Ä‘Ã£ Ä‘Æ°á»£c xá»­ lÃ½
â”‚   â””â”€â”€ *.npy                   # Files dá»¯ liá»‡u Ä‘Ã£ Ä‘Æ°á»£c chia train/val/test
â”œâ”€â”€ Webb/                       # á»¨ng dá»¥ng web
â”‚   â”œâ”€â”€ Back-End/               # API Flask server
â”‚   â”‚   â”œâ”€â”€ app.py              # Flask application
â”‚   â”‚   â”œâ”€â”€ model.py            # Äá»‹nh nghÄ©a mÃ´ hÃ¬nh UNet
â”‚   â”‚   â”œâ”€â”€ requirements.txt    # Dependencies
â”‚   â”‚   â””â”€â”€ best_model.pth      # MÃ´ hÃ¬nh Ä‘Ã£ huáº¥n luyá»‡n
â”‚   â””â”€â”€ Front-End/              # Giao diá»‡n ngÆ°á»i dÃ¹ng
â”‚       â”œâ”€â”€ index.html          # Trang chá»§ upload áº£nh
â”‚       â”œâ”€â”€ edit.html           # Trang chá»‰nh sá»­a vÃ  xem káº¿t quáº£
â”‚       â”œâ”€â”€ script.js           # Logic JavaScript
â”‚       â””â”€â”€ *.css               # Styling
â””â”€â”€ README.md                   # TÃ i liá»‡u nÃ y
```
    best_model_py: https://drive.google.com/file/d/1J1II1ZjSKDkbzBoYZlhArNtBMpCarGN1/view?usp=drive_link (do file quÃ¡ náº·ng khÃ´ng táº£i lÃªn github Ä‘Æ°á»£c)
## ğŸ§  MÃ´ hÃ¬nh Deep Learning

### 1. UNet (model.py)

**Kiáº¿n trÃºc:**
- **Encoder (Downsampling)**: 4 táº§ng convolution blocks vá»›i MaxPooling
- **Bottleneck**: Táº§ng trung gian xá»­ lÃ½ features cÃ³ Ä‘á»™ phÃ¢n giáº£i tháº¥p nháº¥t
- **Decoder (Upsampling)**: 4 táº§ng deconvolution vá»›i skip connections
- **Skip Connections**: Káº¿t ná»‘i trá»±c tiáº¿p tá»« encoder Ä‘áº¿n decoder tÆ°Æ¡ng á»©ng

**Äáº·c Ä‘iá»ƒm ká»¹ thuáº­t:**
```python
# Cáº¥u hÃ¬nh mÃ´ hÃ¬nh
Input channels: 3 (RGB)
Output channels: 12 (12 lá»›p phÃ¢n Ä‘oáº¡n)
Input size: 256x256
Architecture: U-Net vá»›i BatchNorm vÃ  ReLU activation

# Conv Block structure
Conv2d(3x3) â†’ BatchNorm2d â†’ ReLU â†’ Conv2d(3x3) â†’ BatchNorm2d â†’ ReLU
```

**Æ¯u Ä‘iá»ƒm:**
- Skip connections giá»¯ nguyÃªn thÃ´ng tin chi tiáº¿t tá»« táº§ng encoder
- Hiá»‡u quáº£ cho cÃ¡c nhiá»‡m vá»¥ segmentation y táº¿ vÃ  giao thÃ´ng
- Kiáº¿n trÃºc Ä‘Æ¡n giáº£n, dá»… huáº¥n luyá»‡n

### 2. UNet++ (unetPlus.py)

**Kiáº¿n trÃºc:**
- Sá»­ dá»¥ng thÆ° viá»‡n `segmentation_models_pytorch`
- **Encoder**: ResNet34 pre-trained trÃªn ImageNet
- **Decoder**: Nested skip connections vá»›i nhiá»u táº§ng káº¿t ná»‘i chÃ©o
- **Dense Skip Connections**: Káº¿t ná»‘i Ä‘áº­m Ä‘áº·c giá»¯a cÃ¡c táº§ng

**Äáº·c Ä‘iá»ƒm ká»¹ thuáº­t:**
```python
# Cáº¥u hÃ¬nh UNet++
Encoder: "resnet34" with ImageNet pretrained weights
Input channels: 3
Output classes: 12
Architecture: UNet++ with nested skip pathways
```

**Æ¯u Ä‘iá»ƒm:**
- Dense skip connections cáº£i thiá»‡n kháº£ nÄƒng há»c features
- Encoder pre-trained giÃºp há»™i tá»¥ nhanh hÆ¡n
- Hiá»‡u suáº¥t cao hÆ¡n UNet truyá»n thá»‘ng

## ğŸ“Š Dataset vÃ  Xá»­ lÃ½ Dá»¯ liá»‡u

### CamVid Dataset
- **Tá»•ng sá»‘ áº£nh**: 701 áº£nh giao thÃ´ng Ä‘Ã´ thá»‹
- **KÃ­ch thÆ°á»›c**: 960x720 pixels (Ä‘Æ°á»£c resize vá» 256x256)
- **12 lá»›p phÃ¢n Ä‘oáº¡n** vá»›i color mapping:

| Lá»›p | MÃ u RGB | MÃ´ táº£ |
|-----|---------|-------|
| 0 | (128, 128, 128) | Báº§u trá»i (Sky) |
| 1 | (128, 0, 0) | TÃ²a nhÃ  (Building) |
| 2 | (192, 192, 128) | Cá»™t (Pole) |
| 3 | (128, 64, 128) | ÄÆ°á»ng (Road) |
| 4 | (60, 40, 222) | Vá»‰a hÃ¨ (Pavement) |
| 5 | (128, 128, 0) | CÃ¢y (Tree) |
| 6 | (192, 128, 128) | Biá»ƒn bÃ¡o (SignSymbol) |
| 7 | (64, 64, 128) | HÃ ng rÃ o (Fence) |
| 8 | (64, 0, 128) | Xe hÆ¡i (Car) |
| 9 | (64, 64, 0) | NgÆ°á»i Ä‘i bá»™ (Pedestrian) |
| 10 | (0, 128, 192) | NgÆ°á»i Ä‘i xe Ä‘áº¡p (Bicyclist) |
| 11 | (0, 0, 0) | KhÃ´ng xÃ¡c Ä‘á»‹nh (Unlabeled) |

### Data Augmentation
```python
# Training augmentation
train_transform = A.Compose([
    A.HorizontalFlip(p=0.5),          # Láº­t ngang ngáº«u nhiÃªn
    A.RandomBrightnessContrast(p=0.2), # Thay Ä‘á»•i Ä‘á»™ sÃ¡ng/tÆ°Æ¡ng pháº£n
    A.RandomCrop(width=224, height=224), # Cáº¯t ngáº«u nhiÃªn
    A.Rotate(limit=10, p=0.3),        # Xoay nháº¹
    A.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5)),
    ToTensorV2()
])

# Validation/Test augmentation
val_transform = A.Compose([
    A.Resize(height=256, width=256),   # Resize cá»‘ Ä‘á»‹nh
    A.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5)),
    ToTensorV2()
])
```

### Chia dá»¯ liá»‡u
- **Training set**: 70% (~490 áº£nh)
- **Validation set**: 15% (~105 áº£nh)  
- **Test set**: 15% (~106 áº£nh)

## ğŸ”§ Training Process

### Loss Function
**Combined Loss** = 0.7 Ã— CrossEntropyLoss + 0.3 Ã— DiceLoss

```python
def combined_loss(outputs, targets):
    ce_loss = nn.CrossEntropyLoss()
    dice_loss = DiceLoss()
    return 0.7 * ce_loss(outputs, targets) + 0.3 * dice_loss(outputs, targets)
```

**DiceLoss** Ä‘Æ°á»£c thiáº¿t káº¿ Ä‘áº·c biá»‡t cho segmentation:
```python
class DiceLoss(nn.Module):
    def forward(self, inputs, targets):
        intersection = (inputs * targets_one_hot).sum(dim=(2, 3))
        union = inputs.sum(dim=(2, 3)) + targets_one_hot.sum(dim=(2, 3))
        dice = (2. * intersection + smooth) / (union + smooth)
        return 1 - dice.mean()
```

### Optimizer vÃ  Learning Rate
```python
optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)
batch_size = 16
epochs = 50-100 (vá»›i Early Stopping)
```

### Early Stopping
- **Patience**: 10 epochs
- **Metric**: Dice + IoU score
- **Mode**: Maximize (Ä‘iá»ƒm cÃ ng cao cÃ ng tá»‘t)

## ğŸ“ˆ Metrics Ä‘Ã¡nh giÃ¡

### 1. Pixel Accuracy
```python
def pixel_accuracy(preds, masks):
    correct = (preds == masks).float().sum()
    return correct / masks.numel()
```

### 2. Mean Intersection over Union (mIoU)
```python
def mean_iou(preds, masks, num_classes):
    ious = []
    for cls in range(num_classes):
        intersection = ((preds == cls) & (masks == cls)).sum().item()
        union = ((preds == cls) | (masks == cls)).sum().item()
        ious.append(intersection / union if union > 0 else float('nan'))
    return np.nanmean(ious)
```

### 3. Dice Score
```python
def dice_score(preds, masks, num_classes):
    dices = []
    for cls in range(num_classes):
        intersection = ((preds == cls) & (masks == cls)).sum().item()
        total = (preds == cls).sum().item() + (masks == cls).sum().item()
        dices.append(2 * intersection / total if total > 0 else float('nan'))
    return np.nanmean(dices)
```

## ğŸŒ á»¨ng dá»¥ng Web (Webb)

### Back-End (Flask API)

**Cáº¥u trÃºc API:**
```python
# Health check endpoint
GET /api/health
Response: {"status": "ok"}

# Image segmentation endpoint  
POST /api/segment
Input: MultipartForm vá»›i file áº£nh
Output: {
    "success": true,
    "segmented_image": "data:image/png;base64,..."
}
```

**Quy trÃ¬nh xá»­ lÃ½:**
1. **Upload**: Nháº­n áº£nh tá»« client
2. **Preprocessing**: Resize vá» 256x256, normalize
3. **Inference**: Cháº¡y mÃ´ hÃ¬nh UNet Ä‘Ã£ train
4. **Postprocessing**: Chuyá»ƒn prediction thÃ nh mask mÃ u
5. **Response**: Tráº£ vá» áº£nh Ä‘Ã£ phÃ¢n Ä‘oáº¡n dáº¡ng base64

**Dependencies:**
```
flask==2.0.1
flask-cors==3.0.10
torch==1.13.1
torchvision==0.14.1
numpy==1.23.4
opencv-python==4.7.0.72
pillow==9.3.0
albumentations==1.3.0
```

### Front-End (HTML/CSS/JavaScript)

**TÃ­nh nÄƒng:**
- Upload áº£nh vá»›i drag & drop
- Preview áº£nh trÆ°á»›c khi xá»­ lÃ½
- Hiá»ƒn thá»‹ káº¿t quáº£ phÃ¢n Ä‘oáº¡n
- Download áº£nh káº¿t quáº£
- Giao diá»‡n responsive, há»— trá»£ Ä‘a ngÃ´n ngá»¯ (VN/EN)

**Tech Stack:**
- **HTML5**: Cáº¥u trÃºc semantic
- **CSS3**: Styling modern vá»›i Flexbox/Grid
- **Vanilla JavaScript**: Logic xá»­ lÃ½ khÃ´ng dependencies
- **Font**: Google Fonts (Poppins)

## ğŸš€ HÆ°á»›ng dáº«n CÃ i Ä‘áº·t

### 1. Clone Repository
```bash
git clone <repository-url>
cd Segmentation
```

### 2. CÃ i Ä‘áº·t Dependencies

**Cho ImageSegmentation:**
```bash
cd ImageSegmentation
pip install torch torchvision numpy opencv-python albumentations matplotlib tqdm segmentation-models-pytorch
```

**Cho Webb Back-End:**
```bash
cd Webb/Back-End
pip install -r requirements.txt
```

### 3. Chuáº©n bá»‹ Dá»¯ liá»‡u

**Download CamVid dataset:**
```bash
# Äáº·t dá»¯ liá»‡u CamVid vÃ o thÆ° má»¥c ImageSegmentation/CamVid/
# Cháº¡y script xá»­ lÃ½ dá»¯ liá»‡u
cd ImageSegmentation
python data.py
```

### 4. Huáº¥n luyá»‡n MÃ´ hÃ¬nh

**UNet:**
```bash
python model.py
```

**UNet++:**
```bash
python unetPlus.py
```

### 5. Cháº¡y á»¨ng dá»¥ng Web

**Khá»Ÿi Ä‘á»™ng Back-End:**
```bash
cd Webb/Back-End
python app.py
# Server sáº½ cháº¡y táº¡i http://localhost:5000
```

**Má»Ÿ Front-End:**
```bash
cd Webb/Front-End
# Má»Ÿ index.html trong trÃ¬nh duyá»‡t hoáº·c dÃ¹ng live server
```

## ğŸ“Š Káº¿t quáº£ Thá»±c nghiá»‡m

### Hiá»‡u suáº¥t MÃ´ hÃ¬nh

| MÃ´ hÃ¬nh | Pixel Accuracy | mIoU | Dice Score | Training Time |
|---------|---------------|------|------------|---------------|
| UNet | ~85-90% | ~0.72-0.78 | ~0.75-0.82 | 2-3h |
| UNet++ | ~88-92% | ~0.75-0.82 | ~0.78-0.85 | 3-4h |

### Benchmark trÃªn tá»«ng lá»›p

| Lá»›p | IoU | Dice | Äá»™ khÃ³ |
|-----|-----|------|--------|
| Road | >0.9 | >0.95 | Dá»… |
| Building | >0.8 | >0.85 | Trung bÃ¬nh |
| Sky | >0.85 | >0.9 | Dá»… |
| Car | 0.7-0.8 | 0.75-0.85 | Trung bÃ¬nh |
| Pedestrian | 0.5-0.7 | 0.6-0.75 | KhÃ³ |
| Bicyclist | 0.4-0.6 | 0.5-0.7 | Ráº¥t khÃ³ |

## ğŸ”¬ Chi tiáº¿t Ká»¹ thuáº­t

### Optimizations

1. **Mixed Precision Training**: Sá»­ dá»¥ng AMP Ä‘á»ƒ tÄƒng tá»‘c
2. **Data Loading**: Multiprocessing cho DataLoader
3. **Memory Management**: Gradient accumulation cho batch size lá»›n
4. **Model Checkpointing**: LÆ°u best model dá»±a trÃªn validation metrics

### Hardware Requirements

**Minimum:**
- GPU: 4GB VRAM (GTX 1060/RTX 2060)
- RAM: 8GB
- Storage: 5GB free space

**Recommended:**
- GPU: 8GB+ VRAM (RTX 3070/4060+)
- RAM: 16GB+
- Storage: 10GB+ SSD

## ğŸ› ï¸ Troubleshooting

### Lá»—i thÆ°á»ng gáº·p

1. **CUDA out of memory**:
   ```python
   # Giáº£m batch_size xuá»‘ng 8 hoáº·c 4
   train_loader = DataLoader(train_dataset, batch_size=8)
   ```

2. **Model khÃ´ng load Ä‘Æ°á»£c**:
   ```python
   # Kiá»ƒm tra Ä‘Æ°á»ng dáº«n file best_model.pth
   # Äáº£m báº£o model architecture trÃ¹ng khá»›p
   ```

3. **CORS error trong web app**:
   ```python
   # ÄÃ£ enable CORS trong Flask app
   # Kiá»ƒm tra URL API trong JavaScript
   ```


## ğŸ‘¥ ÄÃ³ng gÃ³p

Dá»± Ã¡n má»Ÿ cho viá»‡c cáº£i thiá»‡n vÃ  má»Ÿ rá»™ng:
- ThÃªm cÃ¡c mÃ´ hÃ¬nh segmentation khÃ¡c (DeepLab, PSPNet)
- Cáº£i thiá»‡n giao diá»‡n web
- Tá»‘i Æ°u hÃ³a hiá»‡u suáº¥t inference
- ThÃªm cÃ¡c metrics Ä‘Ã¡nh giÃ¡ khÃ¡c

## ğŸ“„ License

Dá»± Ã¡n Ä‘Æ°á»£c phÃ¡t triá»ƒn cho má»¥c Ä‘Ã­ch nghiÃªn cá»©u vÃ  giÃ¡o dá»¥c.

---

**LiÃªn há»‡**: Äá»ƒ biáº¿t thÃªm thÃ´ng tin chi tiáº¿t vá» dá»± Ã¡n, vui lÃ²ng tham kháº£o cÃ¡c file code vÃ  documentation trong tá»«ng thÆ° má»¥c con.

