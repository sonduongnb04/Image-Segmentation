# D·ª± √°n Ph√¢n ƒëo·∫°n ·∫¢nh Giao Th√¥ng s·ª≠ d·ª•ng Deep Learning

## üìã T·ªïng quan

D·ª± √°n ph√¢n ƒëo·∫°n ·∫£nh giao th√¥ng (Traffic Image Segmentation) s·ª≠ d·ª•ng c√°c m√¥ h√¨nh Deep Learning ti√™n ti·∫øn ƒë·ªÉ ph√¢n ƒëo·∫°n c√°c ƒë·ªëi t∆∞·ª£ng trong ·∫£nh giao th√¥ng th√†nh 12 l·ªõp kh√°c nhau. D·ª± √°n ƒë∆∞·ª£c x√¢y d·ª±ng v·ªõi hai ph·∫ßn ch√≠nh:
- **ImageSegmentation**: X·ª≠ l√Ω d·ªØ li·ªáu, hu·∫•n luy·ªán v√† ƒë√°nh gi√° m√¥ h√¨nh
- **Webb**: Giao di·ªán web ho√†n ch·ªânh v·ªõi Back-End API v√† Front-End ng∆∞·ªùi d√πng

## üéØ M·ª•c ti√™u

- Ph√¢n ƒëo·∫°n ch√≠nh x√°c c√°c ƒë·ªëi t∆∞·ª£ng giao th√¥ng trong ·∫£nh
- H·ªó tr·ª£ 12 l·ªõp ƒë·ªëi t∆∞·ª£ng: B·∫ßu tr·ªùi, T√≤a nh√†, C·ªôt, ƒê∆∞·ªùng, V·ªâa h√®, C√¢y, Bi·ªÉn b√°o, H√†ng r√†o, Xe h∆°i, Ng∆∞·ªùi ƒëi b·ªô, Ng∆∞·ªùi ƒëi xe ƒë·∫°p, Kh√¥ng x√°c ƒë·ªãnh
- Cung c·∫•p giao di·ªán web th√¢n thi·ªán ƒë·ªÉ s·ª≠ d·ª•ng m√¥ h√¨nh
- ƒê·∫°t hi·ªáu su·∫•t cao v·ªõi c√°c metrics nh∆∞ IoU, Dice Score, Pixel Accuracy

## üèóÔ∏è Ki·∫øn tr√∫c H·ªá th·ªëng

```
Segmentation/
‚îú‚îÄ‚îÄ ImageSegmentation/          # Ph·∫ßn x·ª≠ l√Ω d·ªØ li·ªáu v√† hu·∫•n luy·ªán m√¥ h√¨nh
‚îÇ   ‚îú‚îÄ‚îÄ data.py                 # X·ª≠ l√Ω v√† chu·∫©n b·ªã d·ªØ li·ªáu CamVid
‚îÇ   ‚îú‚îÄ‚îÄ model.py                # M√¥ h√¨nh UNet v√† training loop
‚îÇ   ‚îú‚îÄ‚îÄ unetPlus.py             # M√¥ h√¨nh UNet++ v·ªõi encoder pre-trained
‚îÇ   ‚îú‚îÄ‚îÄ demo.py                 # Script demo v√† test m√¥ h√¨nh
‚îÇ   ‚îú‚îÄ‚îÄ processed.py            # Ti·ªÅn x·ª≠ l√Ω d·ªØ li·ªáu
‚îÇ   ‚îú‚îÄ‚îÄ CamVid/                 # D·ªØ li·ªáu g·ªëc CamVid dataset
‚îÇ   ‚îú‚îÄ‚îÄ Camvid_processed/       # D·ªØ li·ªáu ƒë√£ ƒë∆∞·ª£c x·ª≠ l√Ω
‚îÇ   ‚îî‚îÄ‚îÄ *.npy                   # Files d·ªØ li·ªáu ƒë√£ ƒë∆∞·ª£c chia train/val/test
‚îú‚îÄ‚îÄ Webb/                       # ·ª®ng d·ª•ng web
‚îÇ   ‚îú‚îÄ‚îÄ Back-End/               # API Flask server
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ app.py              # Flask application
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ model.py            # ƒê·ªãnh nghƒ©a m√¥ h√¨nh UNet
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ requirements.txt    # Dependencies
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ best_model.pth      # M√¥ h√¨nh ƒë√£ hu·∫•n luy·ªán
‚îÇ   ‚îî‚îÄ‚îÄ Front-End/              # Giao di·ªán ng∆∞·ªùi d√πng
‚îÇ       ‚îú‚îÄ‚îÄ index.html          # Trang ch·ªß upload ·∫£nh
‚îÇ       ‚îú‚îÄ‚îÄ edit.html           # Trang ch·ªânh s·ª≠a v√† xem k·∫øt qu·∫£
‚îÇ       ‚îú‚îÄ‚îÄ script.js           # Logic JavaScript
‚îÇ       ‚îî‚îÄ‚îÄ *.css               # Styling
‚îî‚îÄ‚îÄ README.md                   # T√†i li·ªáu n√†y
```
    best_model_py: https://drive.google.com/file/d/1J1II1ZjSKDkbzBoYZlhArNtBMpCarGN1/view?usp=drive_link (do file qu√° n·∫∑ng kh√¥ng t·∫£i l√™n github ƒë∆∞·ª£c)
## üß† M√¥ h√¨nh Deep Learning

### 1. UNet (model.py)

**Ki·∫øn tr√∫c:**
- **Encoder (Downsampling)**: 4 t·∫ßng convolution blocks v·ªõi MaxPooling
- **Bottleneck**: T·∫ßng trung gian x·ª≠ l√Ω features c√≥ ƒë·ªô ph√¢n gi·∫£i th·∫•p nh·∫•t
- **Decoder (Upsampling)**: 4 t·∫ßng deconvolution v·ªõi skip connections
- **Skip Connections**: K·∫øt n·ªëi tr·ª±c ti·∫øp t·ª´ encoder ƒë·∫øn decoder t∆∞∆°ng ·ª©ng

**ƒê·∫∑c ƒëi·ªÉm k·ªπ thu·∫≠t:**
```python
# C·∫•u h√¨nh m√¥ h√¨nh
Input channels: 3 (RGB)
Output channels: 12 (12 l·ªõp ph√¢n ƒëo·∫°n)
Input size: 256x256
Architecture: U-Net v·ªõi BatchNorm v√† ReLU activation

# Conv Block structure
Conv2d(3x3) ‚Üí BatchNorm2d ‚Üí ReLU ‚Üí Conv2d(3x3) ‚Üí BatchNorm2d ‚Üí ReLU
```

**∆Øu ƒëi·ªÉm:**
- Skip connections gi·ªØ nguy√™n th√¥ng tin chi ti·∫øt t·ª´ t·∫ßng encoder
- Hi·ªáu qu·∫£ cho c√°c nhi·ªám v·ª• segmentation y t·∫ø v√† giao th√¥ng
- Ki·∫øn tr√∫c ƒë∆°n gi·∫£n, d·ªÖ hu·∫•n luy·ªán

### 2. UNet++ (unetPlus.py)

**Ki·∫øn tr√∫c:**
- S·ª≠ d·ª•ng th∆∞ vi·ªán `segmentation_models_pytorch`
- **Encoder**: ResNet34 pre-trained tr√™n ImageNet
- **Decoder**: Nested skip connections v·ªõi nhi·ªÅu t·∫ßng k·∫øt n·ªëi ch√©o
- **Dense Skip Connections**: K·∫øt n·ªëi ƒë·∫≠m ƒë·∫∑c gi·ªØa c√°c t·∫ßng

**ƒê·∫∑c ƒëi·ªÉm k·ªπ thu·∫≠t:**
```python
# C·∫•u h√¨nh UNet++
Encoder: "resnet34" with ImageNet pretrained weights
Input channels: 3
Output classes: 12
Architecture: UNet++ with nested skip pathways
```

**∆Øu ƒëi·ªÉm:**
- Dense skip connections c·∫£i thi·ªán kh·∫£ nƒÉng h·ªçc features
- Encoder pre-trained gi√∫p h·ªôi t·ª• nhanh h∆°n
- Hi·ªáu su·∫•t cao h∆°n UNet truy·ªÅn th·ªëng

## üìä Dataset v√† X·ª≠ l√Ω D·ªØ li·ªáu

### CamVid Dataset
- **T·ªïng s·ªë ·∫£nh**: 701 ·∫£nh giao th√¥ng ƒë√¥ th·ªã
- **K√≠ch th∆∞·ªõc**: 960x720 pixels (ƒë∆∞·ª£c resize v·ªÅ 256x256)
- **12 l·ªõp ph√¢n ƒëo·∫°n** v·ªõi color mapping:

| L·ªõp | M√†u RGB | M√¥ t·∫£ |
|-----|---------|-------|
| 0 | (128, 128, 128) | B·∫ßu tr·ªùi (Sky) |
| 1 | (128, 0, 0) | T√≤a nh√† (Building) |
| 2 | (192, 192, 128) | C·ªôt (Pole) |
| 3 | (128, 64, 128) | ƒê∆∞·ªùng (Road) |
| 4 | (60, 40, 222) | V·ªâa h√® (Pavement) |
| 5 | (128, 128, 0) | C√¢y (Tree) |
| 6 | (192, 128, 128) | Bi·ªÉn b√°o (SignSymbol) |
| 7 | (64, 64, 128) | H√†ng r√†o (Fence) |
| 8 | (64, 0, 128) | Xe h∆°i (Car) |
| 9 | (64, 64, 0) | Ng∆∞·ªùi ƒëi b·ªô (Pedestrian) |
| 10 | (0, 128, 192) | Ng∆∞·ªùi ƒëi xe ƒë·∫°p (Bicyclist) |
| 11 | (0, 0, 0) | Kh√¥ng x√°c ƒë·ªãnh (Unlabeled) |

### Data Augmentation
```python
# Training augmentation
train_transform = A.Compose([
    A.HorizontalFlip(p=0.5),          # L·∫≠t ngang ng·∫´u nhi√™n
    A.RandomBrightnessContrast(p=0.2), # Thay ƒë·ªïi ƒë·ªô s√°ng/t∆∞∆°ng ph·∫£n
    A.RandomCrop(width=224, height=224), # C·∫Øt ng·∫´u nhi√™n
    A.Rotate(limit=10, p=0.3),        # Xoay nh·∫π
    A.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5)),
    ToTensorV2()
])

# Validation/Test augmentation
val_transform = A.Compose([
    A.Resize(height=256, width=256),   # Resize c·ªë ƒë·ªãnh
    A.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5)),
    ToTensorV2()
])
```

### Chia d·ªØ li·ªáu
- **Training set**: 70% (~490 ·∫£nh)
- **Validation set**: 15% (~105 ·∫£nh)  
- **Test set**: 15% (~106 ·∫£nh)

## üîß Training Process

### Loss Function
**Combined Loss** = 0.7 √ó CrossEntropyLoss + 0.3 √ó DiceLoss

```python
def combined_loss(outputs, targets):
    ce_loss = nn.CrossEntropyLoss()
    dice_loss = DiceLoss()
    return 0.7 * ce_loss(outputs, targets) + 0.3 * dice_loss(outputs, targets)
```

**DiceLoss** ƒë∆∞·ª£c thi·∫øt k·∫ø ƒë·∫∑c bi·ªát cho segmentation:
```python
class DiceLoss(nn.Module):
    def forward(self, inputs, targets):
        intersection = (inputs * targets_one_hot).sum(dim=(2, 3))
        union = inputs.sum(dim=(2, 3)) + targets_one_hot.sum(dim=(2, 3))
        dice = (2. * intersection + smooth) / (union + smooth)
        return 1 - dice.mean()
```

### Optimizer v√† Learning Rate
```python
optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)
batch_size = 16
epochs = 50-100 (v·ªõi Early Stopping)
```

### Early Stopping
- **Patience**: 10 epochs
- **Metric**: Dice + IoU score
- **Mode**: Maximize (ƒëi·ªÉm c√†ng cao c√†ng t·ªët)

## üìà Metrics ƒë√°nh gi√°

### 1. Pixel Accuracy
```python
def pixel_accuracy(preds, masks):
    correct = (preds == masks).float().sum()
    return correct / masks.numel()
```

### 2. Mean Intersection over Union (mIoU)
```python
def mean_iou(preds, masks, num_classes):
    ious = []
    for cls in range(num_classes):
        intersection = ((preds == cls) & (masks == cls)).sum().item()
        union = ((preds == cls) | (masks == cls)).sum().item()
        ious.append(intersection / union if union > 0 else float('nan'))
    return np.nanmean(ious)
```

### 3. Dice Score
```python
def dice_score(preds, masks, num_classes):
    dices = []
    for cls in range(num_classes):
        intersection = ((preds == cls) & (masks == cls)).sum().item()
        total = (preds == cls).sum().item() + (masks == cls).sum().item()
        dices.append(2 * intersection / total if total > 0 else float('nan'))
    return np.nanmean(dices)
```

## üåê ·ª®ng d·ª•ng Web (Webb)

### Back-End (Flask API)

**C·∫•u tr√∫c API:**
```python
# Health check endpoint
GET /api/health
Response: {"status": "ok"}

# Image segmentation endpoint  
POST /api/segment
Input: MultipartForm v·ªõi file ·∫£nh
Output: {
    "success": true,
    "segmented_image": "data:image/png;base64,..."
}
```

**Quy tr√¨nh x·ª≠ l√Ω:**
1. **Upload**: Nh·∫≠n ·∫£nh t·ª´ client
2. **Preprocessing**: Resize v·ªÅ 256x256, normalize
3. **Inference**: Ch·∫°y m√¥ h√¨nh UNet ƒë√£ train
4. **Postprocessing**: Chuy·ªÉn prediction th√†nh mask m√†u
5. **Response**: Tr·∫£ v·ªÅ ·∫£nh ƒë√£ ph√¢n ƒëo·∫°n d·∫°ng base64

**Dependencies:**
```
flask==2.0.1
flask-cors==3.0.10
torch==1.13.1
torchvision==0.14.1
numpy==1.23.4
opencv-python==4.7.0.72
pillow==9.3.0
albumentations==1.3.0
```

### Front-End (HTML/CSS/JavaScript)

**T√≠nh nƒÉng:**
- Upload ·∫£nh v·ªõi drag & drop
- Preview ·∫£nh tr∆∞·ªõc khi x·ª≠ l√Ω
- Hi·ªÉn th·ªã k·∫øt qu·∫£ ph√¢n ƒëo·∫°n
- Download ·∫£nh k·∫øt qu·∫£
- Giao di·ªán responsive, h·ªó tr·ª£ ƒëa ng√¥n ng·ªØ (VN/EN)

**Tech Stack:**
- **HTML5**: C·∫•u tr√∫c semantic
- **CSS3**: Styling modern v·ªõi Flexbox/Grid
- **Vanilla JavaScript**: Logic x·ª≠ l√Ω kh√¥ng dependencies
- **Font**: Google Fonts (Poppins)

## üöÄ H∆∞·ªõng d·∫´n C√†i ƒë·∫∑t

### 1. Clone Repository
```bash
git clone <repository-url>
cd Segmentation
```

### 2. C√†i ƒë·∫∑t Dependencies

**Cho ImageSegmentation:**
```bash
cd ImageSegmentation
pip install torch torchvision numpy opencv-python albumentations matplotlib tqdm segmentation-models-pytorch
```

**Cho Webb Back-End:**
```bash
cd Webb/Back-End
pip install -r requirements.txt
```

### 3. Chu·∫©n b·ªã D·ªØ li·ªáu

**Download CamVid dataset:**
```bash
# ƒê·∫∑t d·ªØ li·ªáu CamVid v√†o th∆∞ m·ª•c ImageSegmentation/CamVid/
# Ch·∫°y script x·ª≠ l√Ω d·ªØ li·ªáu
cd ImageSegmentation
python data.py
```

### 4. Hu·∫•n luy·ªán M√¥ h√¨nh

**UNet:**
```bash
python model.py
```

**UNet++:**
```bash
python unetPlus.py
```

### 5. Ch·∫°y ·ª®ng d·ª•ng Web

**Kh·ªüi ƒë·ªông Back-End:**
```bash
cd Webb/Back-End
python app.py
# Server s·∫Ω ch·∫°y t·∫°i http://localhost:5000
```

**M·ªü Front-End:**
```bash
cd Webb/Front-End
# M·ªü index.html trong tr√¨nh duy·ªát ho·∫∑c d√πng live server
```

## üìä K·∫øt qu·∫£ Th·ª±c nghi·ªám

### Hi·ªáu su·∫•t M√¥ h√¨nh

| M√¥ h√¨nh | Pixel Accuracy | mIoU | Dice Score | Training Time |
|---------|---------------|------|------------|---------------|
| UNet | ~85-90% | ~0.72-0.78 | ~0.75-0.82 | 2-3h |
| UNet++ | ~88-92% | ~0.75-0.82 | ~0.78-0.85 | 3-4h |

### Benchmark tr√™n t·ª´ng l·ªõp

| L·ªõp | IoU | Dice | ƒê·ªô kh√≥ |
|-----|-----|------|--------|
| Road | >0.9 | >0.95 | D·ªÖ |
| Building | >0.8 | >0.85 | Trung b√¨nh |
| Sky | >0.85 | >0.9 | D·ªÖ |
| Car | 0.7-0.8 | 0.75-0.85 | Trung b√¨nh |
| Pedestrian | 0.5-0.7 | 0.6-0.75 | Kh√≥ |
| Bicyclist | 0.4-0.6 | 0.5-0.7 | R·∫•t kh√≥ |

## üî¨ Chi ti·∫øt K·ªπ thu·∫≠t

### Optimizations

1. **Mixed Precision Training**: S·ª≠ d·ª•ng AMP ƒë·ªÉ tƒÉng t·ªëc
2. **Data Loading**: Multiprocessing cho DataLoader
3. **Memory Management**: Gradient accumulation cho batch size l·ªõn
4. **Model Checkpointing**: L∆∞u best model d·ª±a tr√™n validation metrics

### Hardware Requirements

**Minimum:**
- GPU: 4GB VRAM (GTX 1060/RTX 2060)
- RAM: 8GB
- Storage: 5GB free space

**Recommended:**
- GPU: 8GB+ VRAM (RTX 3070/4060+)
- RAM: 16GB+
- Storage: 10GB+ SSD

## üõ†Ô∏è Troubleshooting

### L·ªói th∆∞·ªùng g·∫∑p

1. **CUDA out of memory**:
   ```python
   # Gi·∫£m batch_size xu·ªëng 8 ho·∫∑c 4
   train_loader = DataLoader(train_dataset, batch_size=8)
   ```

2. **Model kh√¥ng load ƒë∆∞·ª£c**:
   ```python
   # Ki·ªÉm tra ƒë∆∞·ªùng d·∫´n file best_model.pth
   # ƒê·∫£m b·∫£o model architecture tr√πng kh·ªõp
   ```

3. **CORS error trong web app**:
   ```python
   # ƒê√£ enable CORS trong Flask app
   # Ki·ªÉm tra URL API trong JavaScript
   ```


## üë• ƒê√≥ng g√≥p

D·ª± √°n m·ªü cho vi·ªác c·∫£i thi·ªán v√† m·ªü r·ªông:
- Th√™m c√°c m√¥ h√¨nh segmentation kh√°c (DeepLab, PSPNet)
- C·∫£i thi·ªán giao di·ªán web
- T·ªëi ∆∞u h√≥a hi·ªáu su·∫•t inference
- Th√™m c√°c metrics ƒë√°nh gi√° kh√°c

## üìÑ License

D·ª± √°n ƒë∆∞·ª£c ph√°t tri·ªÉn cho m·ª•c ƒë√≠ch nghi√™n c·ª©u v√† gi√°o d·ª•c.

---

**Li√™n h·ªá**: ƒê·ªÉ bi·∫øt th√™m th√¥ng tin chi ti·∫øt v·ªÅ d·ª± √°n, vui l√≤ng tham kh·∫£o c√°c file code v√† documentation trong t·ª´ng th∆∞ m·ª•c con.

